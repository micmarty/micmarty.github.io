section_title: Projects Archive

# --------------------------------------------------------------------------------------------------------------------
# 0. Instronizer
first_project:
  project_title: Instronizer
  labels:
    - audio
    - machine learning
  badge: My BSc
  short_description: Musical instruments identification system based on usage of Deep Neural Networks
  long_description:
    - expandable: false
      paragraph: |
        <br/>
        <b>Engineer's diploma project</b> made in cooperation with Maciej Rutkowski and Filip Schodowski.
        A lightweight convolutional neural network was trained, achieving <b>86%</b> accuracy on our test set.

        It can identify 6 predominant instruments right now, but adding more of them would be just upgrading the same system.

        1 second is enough to get an accurate classification result but 3s segments are performing a little bit better.
        The neural network is fed with mel-scaled spectrograms instead of raw audio.
    - expandable: true
      paragraph: |
        <hr class='divider'>
        At the beginning we were using IRMAS dataset which turned out later to be not good quality:
        <ul>
          <li>Small and unbalanced training set - 19 to 39 minutes per instrument</li>
          <li>Many wrong annotated labels</li>
          <li>Multiple excerpts from one song were extracted, decreasing diversity of the data</li>
          <li>Testing set has completely different strategy of labeling than the training one</li>
        </ul>
        Because of this a <b>new dataset</b> consisting of YouTube clips was created:
        <ul>
          <li>Almost 4 times bigger (per instrument)
            <ul>
              <li>2 hours for training
              <li>30 minutes for validation
              <li>30 minutes for testing
            </ul>
          </li>
          <li>Fully handmade work</li>
        </ul>
        For the purpose of this project 3 main components were designed and implemented:
        <ul>
        <li>Data processor (audio excerpt -> spectrogram)</li>
        <li>Classifier based on Google's MobileNet CNN architecture</li>
        <li>Material Design web app written in Python (Flask) and JavaScript</li>
  image_path: false
  video_path: <iframe width="100%" height="490" src="https://www.youtube-nocookie.com/embed/y9PxS5gOlJU?autoplay=1?start=356" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
  # Edit link: http://sendvid.com/40740549?secret=2140d27f-7f80-4e36-bfaf-4c3943f3b61a
  link: https://github.com/micmarty/Instronizer

  buttons:
    - name: ResearchGate
      link: https://www.researchgate.net/project/Musical-instruments-recognition-in-polyphonic-audio-deep-neural-network

    - name: Thesis PDF (PL)
      link: https://www.researchgate.net/profile/Michal_Martyniak/project/Musical-instruments-recognition-in-polyphonic-audio-deep-neural-network/attachment/5aa99538b53d2f0bba581394/AS:604197108060161@1521063224551/download/Instronizer_Thesis_PL.pdf?context=ProjectUpdatesLog

    - name: Source code
      link: https://github.com/micmarty/Instronizer

# --------------------------------------------------------------------------------------------------------------------
# 2. RustOS
second_project:
  project_title: RustOS
  labels:
    - low-level
  badge: toy project
  short_description: A proof-of-concept operating system written in awesome Rust language + some assembly code
  long_description:
    - expandable: false
      paragraph: |
        <br/>
        It is capable of reading scancodes (keys), dealing with the text mode. 
        I was able to turn on paging, protected 64-bit mode and execute Rust unsafe code (which runs even on barebone metal, without kernel libraries obviously).
        There is generated ISO image, which is enough to run inside QEMU + debugger (e.g. gdb).

        <b>I am proud of it</b>, but for those, who haven't experienced writing own OS firsthand, it may look crappy and straightforward.
        Even my lecturer wasn't 100% sure if it is feasable in Rust <i class="fa fa-smile-o" aria-hidden="true"></i>.

  image_path: false
  video_path:
    <video min-width="100%" width="100%" height="100%" min-height="100%" controls>
    <source src="images/projects/major/rustos_in_qemu.mp4" type="video/mp4">
    Your browser does not support the video tag.
    </video>
  link: https://github.com/micmarty/RustOS_toy_project

  buttons:
    - name: Source code
      link: https://github.com/micmarty/RustOS_toy_project

# --------------------------------------------------------------------------------------------------------------------
# 3. Kainos Fund Tracker 2016
third_project:
  project_title: Fund Tracker
  labels:
    - Ruby on Rails
  badge: toy app
  short_description: App which renders a single chart from market shares data (as CSV file) and calculates the benefit from bank deposit.
  long_description:
    - expandable: false
      paragraph: |
        One of my very first apps, but now I know <b>what was wrong</b>.
        There is not much of Ruby code, mostly vanilla JavaScript.
        It has bugs <i class="fa fa-smile-o" aria-hidden="true"></i>
    - expandable: false
      paragraph: |
        <h4 class="level-title">Next time I would pick:</h4>
        <ul>
          <li>TypeScript</li>
          <li>Middleman -> static site generator</li>
          <li>simple_form gem</li>
          <li>Google Charts</li>
          <li>Material Design + CSS Grid instead of Bootstrap</li>
        </ul>
  image_path: images/projects/major/fund_tracker_chart.png
  link: https://github.com/micmarty/fund_tracker

  buttons:
    - name: Source Code
      link: https://github.com/micmarty/fund_tracker
