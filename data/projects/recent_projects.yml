section_title: Recent Projects
# --------------------------------------------------------------------------------------------------------------------
first_project:
  project_title: Command-driven trajectory planning and following for a self-driving car in a simulated environment
  labels:
    - CARLA simulator
    - vision-based
    - supervised
  badge: My MSc
  short_description: My master's thesis about fully autonomous agent that includes perception, planning and control
  long_description:
    - expandable: false
      paragraph: |

        My agent is able to <b>navigate from A to B</b> with respect to human input, like: turn left, right, keep lane, go straight (GPS-like navigation). The only input given for the planning module (neural network) is: 224x224 RGB image + command. 
        Output is a ~15m trajectory ahead of agent's car. Most important thing to note is that <b>predicted trajectory does not says "how to drive" but "where is the legal path that should be followed"</b>.

        Besides planning, agent can detect and react to traffic lights (simple perception module made with TensorFlow Object Detection API).

        Proposed method of <b>Reference Trajectory Approximation</b> allows for better visual understanding how agent percives the environment in the long run.
        Although the internals of this system are not that much compilcated as it may seem (in comparison with real-world systems), but it took a very long time to do research, gather data, implement and evaluate.

        <b>More videos + extras (MLinPL):</b> <a href="https://drive.google.com/open?id=1Qrm5noTVHSC7yQw0NQTOlLunUHTke4lN" target="_blank">link</a>
        Feel free to <b>contact me directly if we have common research interests</b> or my work just caught your eye ðŸ˜‰.
        <!-- Seminarka PG 15.04.2019 (ENG) - milestones: <a href="https://docs.google.com/presentation/d/10EDFtKnHjQCcLoQ4SHXRuZHgmUHgD-azZSHZeRViCzE/edit?usp=sharing -->
  video_path: |
    <iframe width="100%" height="490" src="https://www.youtube.com/embed/d3xyjut2gWw?autoplay=1" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
    <!-- <iframe src="https://docs.google.com/presentation/d/e/2PACX-1vTmvj-SDdWNfiVog7QPM46hl0yPuGJNOPKxTQ2YOwWcCZHKsUk-BWXZx2XPgyCXjzWwRA9ejxzCkopq/embed?start=true&loop=true&delayms=3000" frameborder="0" width="100%" height="490" allowfullscreen="true" mozallowfullscreen="true" webkitallowfullscreen="true"></iframe> -->
    <!-- <iframe src="https://docs.google.com/presentation/d/e/2PACX-1vQuGj9DRZ-LfheFwRGICpl93mzybDCpEaEPvKzPeP1J9QoaKTgFu2vTwf_Ey_8jm-nIg8apjwb0Mr5x/embed?start=true&loop=true&delayms=3000" frameborder="0" width="100%" height="490" allowfullscreen="true" mozallowfullscreen="true" webkitallowfullscreen="true"></iframe> -->
  buttons:
    - name: MLinPL Poster
      link: https://drive.google.com/open?id=1pNrkshVnNiNE9TEEa6w1Rsv8v9JEYcB5
    - name: Thesis PDF (PL)
      link: https://drive.google.com/open?id=13CXULSNrVkydnqRSUOggkUtkPCJcKUOi
    - name: Project summary on YouTube (ENG)
      link: https://youtu.be/PkTxzsUUCgc
    # - Slides (PL) -> not relevant anymore
    #   https://docs.google.com/presentation/d/1tYvrb2Vâ”‚â”‚
# --------------------------------------------------------------------------------------------------------------------
second_project:
  project_title: Bird-eye's view for CARLA
  labels:
    - open source
    - deepsense.ai
  badge: SDC
  short_description: 2D Visualization tool has been used as one of possible inputs to our RL model in CARLA Real Traffic Scenarios evaluation
  long_description:
    - expandable: true
      html_partial_path: partials/projects/birdview_table
      paragraph: This proj

  image_path: images/projects/recent/ngsim-freeway.gif
  buttons:
    - name: PyPI package
      link: https://pypi.org/project/carla-birdeye-view/
    - name: Source Code
      link: https://github.com/deepsense-ai/carla-birdeye-view
    - name: Research results
      link: https://sites.google.com/view/carla-real-traffic-scenarios/home
    - name: Paper on arxiv
      link: https://arxiv.org/abs/2012.11329
# --------------------------------------------------------------------------------------------------------------------
third_project:
  project_title: TensorHive
  labels:
    - nvidia-smi
    - open source
  badge: false
  short_description: Lightweight computing resource management tool for executing machine learning applications in distributed TensorFlow
  long_description:
    - expandable: false
      paragraph: |
        We've just started making an open-source solution for distributed trainings in TensorFlow.
        It will:
        <ul>
          <li>Launch with a single command</li>
          <li>Have a dashboard built with Material Design components (Google Android style)
          <li>Communicate over ssh</li>
          <li>Monitor resources like: GPU, memory load, etc.</li>
        </ul>
        The project has started within <a href="http://gradient.eti.pg.gda.pl/" target="_blank"><img src="images/gradient_logo_small.png" style="margin-bottom: 0px"><b>GradientPG</b></a> (Student Research Group I participate in).

  image_path: images/projects/major/tensorhive_dashboard.jpeg
  link: https://github.com/roscisz/TensorHive
  buttons:
    - name: Source Code
      link: https://github.com/roscisz/TensorHive
    - name: Article (PL)
      link: https://gradient.eti.pg.gda.pl/projekty/2017/10/07/projekt-tensor-hive.html
    - name: Article (ENG)
      link: https://gradient.eti.pg.gda.pl/en/projects/2017/10/07/projekt-tensor-hive.html
# --------------------------------------------------------------------------------------------------------------------
fourth_project:
  project_title: Audio signal analysis in Python with Librosa
  labels:
    - audio
    - own research
  badge: hobby
  short_description: |
    I had to do some research about choosing the best model for my neural network.
    My journey started with librosa - it can transform an audio excerpt into many visual representations, 
    e.g. spectogram or chroma and has very useful features like beat detection.
  long_description:
    - expandable: false
      paragraph: "" # NO DESCRIPTION

  image_path: images/projects/major/librosa_chroma.png
  link: https://github.com/micmarty/audio-preprocessing-exercises-with-librosa/blob/master/librosa_sandbox_1.ipynb
  buttons:
    - name: Source Code
      link: https://github.com/micmarty/audio-preprocessing-exercises-with-librosa/blob/master/librosa_sandbox_1.ipynb
